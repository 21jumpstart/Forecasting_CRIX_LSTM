{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Data Analytics\n",
    "Estimating volatility of the Crix index with a LSTM neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukas/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Load Libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request, json \n",
    "\n",
    "from keras.optimizers       import Adam\n",
    "from keras.models           import Sequential\n",
    "from keras.layers           import Dense\n",
    "from keras.layers           import LSTM\n",
    "from keras.models           import load_model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "look_back = 10\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(\"http://thecrix.de/data/crix.json\") as url:\n",
    "    data = json.loads(url.read().decode())\n",
    "    \n",
    "#Convert the data in a pandas dataframe\n",
    "crix_data = pd.DataFrame(data = data[:-1]) \n",
    "crix_data = crix_data.set_index('date')\n",
    "crix_data['returns'] = np.log(crix_data.price / crix_data.price.shift(1))\n",
    "crix_data['vol'] = np.square(crix_data['returns'])\n",
    "crix_data['ewma'] = crix_data['vol'].ewm(span = look_back).mean()\n",
    "\n",
    "#Remove the first row containing 'Nan' Values\n",
    "crix_data.drop(crix_data.index[0], inplace = True)\n",
    "\n",
    "#Display the first 5 rows of the dataset\n",
    "crix_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(crix_data['vol'].values)\n",
    "plt.plot(crix_data['ewma'].values, color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_series = crix_data['ewma'].values\n",
    "return_series = return_series.reshape(len(return_series),1)\n",
    "return_series = return_series.astype('float32')\n",
    "\n",
    "\n",
    "#Normalize the values to a range from zero to 1\n",
    "scaler            = MinMaxScaler(feature_range=(0, 1))\n",
    "return_series     = scaler.fit_transform(return_series)\n",
    "\n",
    "#Split the data into a training and test set\n",
    "#We are using 80 percent of the data as training set and 20% as the test set. \n",
    "train_size  = int(len(return_series) * 0.80)\n",
    "test_size   = len(return_series) - train_size\n",
    "\n",
    "train, test = return_series[0:train_size], return_series[train_size:len(return_series)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Data Set\n",
    "#dataX is the is the rolling window of past oberservations \n",
    "#dataY becomes the the value that is one day ahead of the rolling window. \n",
    "#This is the label/prediction for the past values\n",
    "\n",
    "def create_dataset(time_series, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    \n",
    "    for i in range(1,len(time_series) - look_back - 1):\n",
    "        \n",
    "        x = time_series[i:i + look_back]\n",
    "        dataX.append(x)\n",
    "        \n",
    "        y = time_series[i + look_back + 1]\n",
    "        dataY.append(y)\n",
    "           \n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataset with rolling window for the training set and test set\n",
    "trainX, trainY  = create_dataset(train, look_back)\n",
    "testX, testY    = create_dataset(test, look_back)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "trainX  = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX   = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "#LSTM Neural Network with 128 Nodes is 3 Layers, followed by dense layer that outputs the prediction\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences = True, input_shape=(1, look_back)))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1))\n",
    "optimizer = Adam(lr = 0.0001)\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "\n",
    "#TODO: Try diffrent (smaller) model architectures, add regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model, epochs is the number of iterations\n",
    "\n",
    "model.fit(trainX, trainY, epochs = epochs, batch_size = 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Output/Model_LB-'+ str(look_back) + '_EP-'+str(epochs)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions \n",
    "trainPredict    = model.predict(trainX)\n",
    "testPredict     = model.predict(testX)\n",
    "\n",
    "#Inverse the normalization procedure of the data\n",
    "trainY = np.reshape(trainY,(trainY.shape[0],))\n",
    "testY  = np.reshape(testY,(testY.shape[0],))\n",
    "\n",
    "trainPredict    = scaler.inverse_transform(trainPredict)\n",
    "trainY          = scaler.inverse_transform([trainY])\n",
    "testPredict     = scaler.inverse_transform(testPredict)\n",
    "testY           = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.6f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.6f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(crix_data['vol'].values, color = 'grey')\n",
    "\n",
    "# Shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(return_series)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# Shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(return_series)\n",
    "testPredictPlot[:, :]= np.nan\n",
    "testPredictPlot[len(trainPredict) + (look_back * 2) + 2:len(return_series)-2, :] = testPredict\n",
    "\n",
    "# Plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(return_series), label = 'Vol')\n",
    "plt.plot(trainPredictPlot, label = 'Prediction on Training Set')\n",
    "plt.plot(testPredictPlot, label = 'Prediction on Test Set')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Trading Days')\n",
    "plt.ylabel('Volatility')\n",
    "plt.savefig('Output/Plot_LB-'+ str(look_back) + '_EP-'+str(epochs)+'.png', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
